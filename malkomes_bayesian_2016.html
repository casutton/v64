<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Bayesian optimization for automated model selection | AutoML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Bayesian optimization for automated model selection">

  <meta name="citation_author" content="Malkomes, Gustavo">

  <meta name="citation_author" content="Schaff, Chip">

  <meta name="citation_author" content="Garnett, Roman">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of the 2016 Workshop on Automatic Machine Learning">
<meta name="citation_firstpage" content="41">
<meta name="citation_lastpage" content="47">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v64/malkomes_bayesian_2016.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Bayesian optimization for automated model selection</h1>

	<div id="authors">
	
		Gustavo Malkomes,
	
		Chip Schaff,
	
		Roman Garnett
	<br />
	</div>
	<div id="info">
		Proceedings of the 2016 Workshop on Automatic Machine Learning,
		pp. 41–47, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Despite the success of kernel-based nonparametric methods, kernel selection still requires considerable expertise, and is often described as a “black art.” We present a sophisticated method for automatically searching for an appropriate kernel from an infinite space of potential choices. Previous efforts in this direction have focused on traversing a kernel grammar, only examining the data via computation of marginal likelihood. Our proposed search method is based on Bayesian optimization in model space, where we reason about model evidence as a function to be maximized. We explicitly reason about the data distribution and how it induces similarity between potential model choices in terms of the explanations they can offer for observed data. In this light, we construct a novel kernel between models to explain a given dataset. Our method is capable of finding a model that explains a given dataset well without any human assistance, often with fewer computatio! ns of model evidence than previous approaches, a claim we demonstrate empirically.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="malkomes_bayesian_2016.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
